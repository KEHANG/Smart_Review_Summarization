{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from srs.predictor import loadTrainedPredictor\n",
    "from srs.utilities import loadUsefulTrainingData\n",
    "from srs import settings\n",
    "from srs.Model_Word2Vec import AspectPatterns, distill_dynamic, static_aspect_to_vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.utils import column_or_1d\n",
    "from srs.predictor import MaxEntropy_Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up word2vec predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_predictor = loadTrainedPredictor('Word2Vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load training sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "static_traning_data_dir = settings[\"static_training_data\"]\n",
    "sentences = loadUsefulTrainingData(static_traning_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create feature vec for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aspectPattern_names = ['adj_nn','nn']\n",
    "aspectPatterns = AspectPatterns(aspectPattern_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=w2v_predictor.static_aspects_all['static_aspect_list_fortraining'])\n",
    "target = pd.DataFrame(columns=['Prod_Feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sen0 in sentences:\n",
    "\n",
    "    distill_dynamic(sen0, aspectPatterns)\n",
    "\n",
    "    #transform the sentence's word2vec_features to vectors\n",
    "    word2vec_features = []\n",
    "    for item in sen0.word2vec_features_list:\n",
    "        word2vec_features=word2vec_features + item\n",
    "    vec_list=[]\n",
    "    for dynamic_aspect in word2vec_features:\n",
    "        dynamic_aspect_splitted=dynamic_aspect.split(' ')\n",
    "        aspect_phrase_vec=[]\n",
    "        for word in dynamic_aspect_splitted:\n",
    "            if word in w2v_predictor.model:\n",
    "                aspect_word_vec=w2v_predictor.model[word]\n",
    "                aspect_phrase_vec.append(aspect_word_vec)\n",
    "        if aspect_phrase_vec:\n",
    "            vec_list.append(aspect_phrase_vec)\n",
    "\n",
    "    num_static_aspect = len(w2v_predictor.static_aspects_all['static_aspect_list_fortraining'])\n",
    "    static_wordlist_vec = static_aspect_to_vec(w2v_predictor.static_aspects_all, w2v_predictor.model)\n",
    "    if vec_list:\n",
    "        similarity_matrix=np.zeros([len(vec_list),num_static_aspect])\n",
    "        for i in range(len(vec_list)):\n",
    "            for j in range(num_static_aspect):   \n",
    "                similarity_item_matrix=np.zeros([len(vec_list[i]),len(static_wordlist_vec[j])])\n",
    "                for kk in range(len(vec_list[i])):\n",
    "                    for ll in range(len(static_wordlist_vec[j])):\n",
    "                        similarity_item_matrix[kk][ll]=np.dot(vec_list[i][kk],static_wordlist_vec[j][ll])\n",
    "\n",
    "                similarity_item_row=np.max(similarity_item_matrix,axis=1)\n",
    "                similarity_item=np.sum(similarity_item_row)\n",
    "                similarity_matrix[i][j]=similarity_item\n",
    "\n",
    "    useful_features_vec = np.max(similarity_matrix, axis=0)\n",
    "    \n",
    "    row = pd.DataFrame([useful_features_vec],\n",
    "                       columns = w2v_predictor.static_aspects_all['static_aspect_list_fortraining'])\n",
    "    df = df.append(row,ignore_index=True)\n",
    "    \n",
    "    row_target = pd.DataFrame([sen0.labeled_aspects],columns=['Prod_Feat'])\n",
    "    target = target.append(row_target,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(df.index, test_size=0.25, random_state=42)\n",
    "X_train  = df.iloc[train_idx]\n",
    "X_test = df.iloc[test_idx]\n",
    "y_train = target.iloc[train_idx].values.ravel()\n",
    "y_test = target.iloc[test_idx].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for kernel in ('linear', 'rbf', 'poly'):\n",
    "    print \"================kernel: {0}=========================\".format(kernel)\n",
    "    w2v_svm = svm.SVC(kernel=kernel, gamma=11)\n",
    "    w2v_svm.fit(X_train, y_train)\n",
    "    y_predicted = w2v_svm.predict(X_test)\n",
    "    target_names = target.Prod_Feat.unique()\n",
    "    print(classification_report(y_test, y_predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Use pure word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_w2v = []\n",
    "for idx in test_idx:\n",
    "    sentences_w2v.append(sentences[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = w2v_predictor.predict_for_sentences(sentences_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"================kernel: {0}=========================\".format('pure word2vec')\n",
    "print(classification_report(y_test, y_predicted, target_names=np.insert(target_names, 0, 'useless')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
